{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b48857ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning output db directory already exist: /home/jpereira/OEs/Results/OE1/NamSeqs/Data/block_map/trimm_nam/clean_fasta_db\n",
      "makeblastdb ran successfully.\n",
      "Running: blastn -query /home/jpereira/OEs/Results/OE1/NamSeqs/Data/TrimNam/NamBlocks_trim/block_iterations/1/retrieve/regions.fasta -db /home/jpereira/OEs/Results/OE1/NamSeqs/Data/block_map/trimm_nam/clean_fasta_db/cluster_1.fasta -out /home/jpereira/OEs/Results/OE1/NamSeqs/Data/block_map/trimm_nam/blastn.auto_bl_clean_db.tsv -num_threads 10 -reward 1 -gapextend 2 -gapopen 5 -penalty -2 -word_size 15 -outfmt '6 qseqid sseqid pident length mismatch gapopen qstart qend sstart send evalue bitscore qlen slen'\n",
      "blastn ran successfully.\n",
      "Aligments where the blocks don't have its initial bases on the read: 32 \n",
      "Aligments where the blocks don't have its end bases on the read: 58 \n",
      "Total Aligments: 3145 \n",
      "\n",
      "Exponential: y = a * exp(-b*x) + c\n",
      "----------------------------------\n",
      "n=24  k=3\n",
      "R² = 0.6217\n",
      "AIC = 244.255   AICc = 245.455   BIC = 247.789\n",
      "RSS = 4.92e+05\n",
      "\n",
      "Parameters (estimate ± SE) [t, p]:\n",
      "       a = 2561.95 ± 1272.66   [t=2.013, p=0.0571]\n",
      "       b = 0.0321509 ± 0.0107681   [t=2.986, p=0.00705]\n",
      "       c = 93.5912 ± 54.8026   [t=1.708, p=0.102] \n",
      "\n",
      "Power-law: y = a * x^(-b)\n",
      "-------------------------\n",
      "n=24  k=2\n",
      "R² = 0.6240\n",
      "AIC = 242.112   AICc = 242.683   BIC = 244.468\n",
      "RSS = 4.89e+05\n",
      "\n",
      "Parameters (estimate ± SE) [t, p]:\n",
      "       a = 192275 ± 195678   [t=0.983, p=0.336]\n",
      "       b = 1.4813 ± 0.25001   [t=5.925, p=5.81e-06] \n",
      "\n",
      "Saved figure to /home/jpereira/OEs/Results/OE1/NamSeqs/Visuals/block_map/trimm_nam/fit_comparison.png\n",
      "Saved summaries to /home/jpereira/OEs/Results/OE1/NamSeqs/Data/block_map/trimm_nam/exp_fit_summary.txt and /home/jpereira/OEs/Results/OE1/NamSeqs/Data/block_map/trimm_nam/power_fit_summary.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1128945/1771385622.py:269: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  total_coverage_s = sorted_df.groupby('sseqid').apply(lambda x: total_coverage(x, use='subject'))\n"
     ]
    }
   ],
   "source": [
    "#### - - - Loading libraries and Input - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "\n",
    "from utils.blast_utils import makeblast_db, blastn, default_blast_columns, alignment_absolute_start_end, total_coverage, unmapped_subject_regions\n",
    "#from utils.block_utils import run_blast_mapping\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import AutoMinorLocator\n",
    "from pathlib import Path\n",
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# TO DO:\n",
    "# Then find the number of time each block map, te proportion of bases mapped by each block (two barplots, and two stacked plots) \n",
    "\n",
    "test=True\n",
    "if test:\n",
    "    input_clean_fasta = Path(\"/home/jpereira/OEs/Results/OE1/NamSeqs/Data/mcl_clustering/sequneces_clusters/cluster_1.fasta\")\n",
    "    output_map_data_dir = Path(\"/home/jpereira/OEs/Results/OE1/NamSeqs/Data/block_map\")\n",
    "    output_map_vis_dir = Path(\"/home/jpereira/OEs/Results/OE1/NamSeqs/Visuals/block_map\")\n",
    "    \n",
    "    work_name = \"trimm_nam\"\n",
    "    input_blocks_fasta = Path(\"/home/jpereira/OEs/Results/OE1/NamSeqs/Data/TrimNam/NamBlocks_trim/block_iterations/1/retrieve/regions.fasta\")\n",
    "    \n",
    "    #work_name = \"auto_blocks\"\n",
    "    #input_blocks_fasta = Path(\"/home/jpereira/OEs/Results/OE1/NamSeqs/Data/define_blocks/kmer30/block_iterations/1/retrieve/regions.fasta\")\n",
    "\n",
    "if work_name:\n",
    "    output_map_data_dir = output_map_data_dir / work_name\n",
    "    output_map_vis_dir = output_map_vis_dir / work_name\n",
    "    \n",
    "output_map_data_dir.mkdir(exist_ok=True, parents=True)\n",
    "output_map_vis_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "logs_dir = output_map_data_dir / 'logs'\n",
    "logs_dir.mkdir(exist_ok=True)\n",
    "\n",
    "#### - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "\n",
    "#### - - Mapping blocks to the cleaned reads - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "\n",
    "clean_db = makeblast_db(seqs_path= input_clean_fasta ,db_out=output_map_data_dir / \"clean_fasta_db\", log_file=logs_dir / \"make_db.log\")\n",
    "blast_tsv = output_map_data_dir / \"blastn.auto_bl_clean_db.tsv\"\n",
    "blastn(blast_input_seqs=input_blocks_fasta,\n",
    "       blast_db_file=clean_db,\n",
    "       word_size=15,\n",
    "       num_threads=10,\n",
    "       blast_output_table_tsv= blast_tsv,\n",
    "       log_file= logs_dir / \"blastn.auto_bl.log\")\n",
    "\n",
    "# Load blast_df\n",
    "blast_df = pd.read_csv(blast_tsv, sep='\\t', header=None)\n",
    "blast_df.columns = default_blast_columns\n",
    "\n",
    "# Filter blast_df\n",
    "blast_df = blast_df[blast_df['pident'] > 0.9] \n",
    "blast_df = blast_df[blast_df['gapopen'] < 20]\n",
    "blast_df = blast_df[blast_df['length'] > 20]\n",
    "\n",
    "#### - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "\n",
    "#### - - Alignment length vs Block Length (All and only Contained BLocks)- - - - - - - - - -\n",
    "\n",
    "(blast_df['length'] / blast_df['qlen']).hist(bins=50)\n",
    "plt.title(\"Aligment Length vs Block Length\")\n",
    "plt.savefig(output_map_vis_dir / \"hist.block-length_vs_aligment-length.png\")\n",
    "plt.close()\n",
    "\n",
    "blast_df = alignment_absolute_start_end(blast_df)\n",
    "\n",
    "margin = 10\n",
    "s_contained = (blast_df['a.qstart'] <= 1 + margin ) \n",
    "e_contained = (blast_df['a.qend'] >= blast_df['qlen'] - margin )\n",
    "\n",
    "contained_df = blast_df[s_contained & e_contained].copy()\n",
    "(contained_df['qlen'] / contained_df['length']).hist(bins=50)\n",
    "plt.title(\"Alignment Length vs. Block Length \\n (Blocks Fully Contained in the Reads)\")\n",
    "plt.savefig(output_map_vis_dir / \"hist_block-length_vs_alignment-length_contained.png\")\n",
    "plt.close()\n",
    "\n",
    "#### - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "\n",
    "#### - - Alignment length vs Block Length (Normalized) - - - - - - - - - - - - - - - - - - -\n",
    "\n",
    "# Select the blocks with only the start position contained on the read\n",
    "s_contained_df = blast_df[s_contained &  ~e_contained].copy()\n",
    "# Select alignments where 'a.send' coincides with 'slen' (within a tolerance margin)\n",
    "s_contained_df = s_contained_df[s_contained_df['a.send'] >= s_contained_df['slen'] - margin]\n",
    "s_no_containded_df = s_contained_df[s_contained_df['a.send'] < s_contained_df['slen'] - margin]\n",
    "# Re-estimate the alignment length only taking into account the region inside the block\n",
    "s_contained_df['c.qlen'] = s_contained_df['slen'] - s_contained_df['a.sstart'] + 1\n",
    "\n",
    "# Select the blocks with only the end position contained on the read\n",
    "e_contained_df = blast_df[~s_contained &  e_contained].copy()\n",
    "# Select alignments where 'a.sstart' is at the beginning of the read (within a tolerance margin)\n",
    "e_contained_df = e_contained_df[e_contained_df['a.sstart'] <= 1 + margin]\n",
    "e_no_containded_df = e_contained_df[e_contained_df['a.sstart'] > 1 + margin]\n",
    "# Re-estimate the alignment length only taking into account the region inside the block\n",
    "e_contained_df['c.qlen'] = e_contained_df['a.send']\n",
    "\n",
    "#Define c.qlen for the blocks fully contained inside the reads\n",
    "contained_df['c.qlen'] = contained_df['qlen']\n",
    "\n",
    "curated_df = pd.concat([contained_df, s_contained_df, e_contained_df]) \n",
    "\n",
    "plt.title(\"Alignment Length vs. Block Length \\n (Block Length Normalized at the Edge Positions)\")\n",
    "(curated_df['length'] / curated_df['c.qlen']).hist()\n",
    "plt.savefig(output_map_vis_dir / \"hist_block-length_vs_alignment-length_normalized.png\")\n",
    "plt.close()\n",
    "\n",
    "print(f\"Aligments where the blocks don't have its initial bases on the read: {e_contained_df.shape[0]} \")\n",
    "print(f\"Aligments where the blocks don't have its end bases on the read: {s_contained_df.shape[0]} \")\n",
    "print(f\"Total Aligments: {curated_df.shape[0]} \\n\")\n",
    "\n",
    "#### - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "\n",
    "#### - - - Number of apariences by block - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import t\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Models\n",
    "def exp_decay(x, a, b, c):\n",
    "    # y = a * exp(-b*x) + c\n",
    "    return a * np.exp(-b * x) + c\n",
    "\n",
    "def power_law(x, a, b):\n",
    "    # y = a * x^(-b)\n",
    "    return a * np.power(x, -b)\n",
    "\n",
    "# Utilities\n",
    "def fit_stats(x, y, model, popt, pcov):\n",
    "    yhat = model(x, *popt)\n",
    "    resid = y - yhat\n",
    "\n",
    "    n = len(y)\n",
    "    k = len(popt)\n",
    "    rss = np.sum(resid**2)\n",
    "    tss = np.sum((y - np.mean(y))**2)\n",
    "    r2  = 1 - rss / tss if tss > 0 else np.nan\n",
    "\n",
    "    # parameter SEs, t-stats, p-values (approximate, from pcov)\n",
    "    se = np.sqrt(np.diag(pcov))\n",
    "    # guard against zero division\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        tvals = popt / se\n",
    "    df = max(n - k, 1)\n",
    "    pvals = 2 * (1 - t.cdf(np.abs(tvals), df=df))\n",
    "\n",
    "    # information criteria\n",
    "    aic  = n * np.log(rss / n) + 2 * k\n",
    "    aicc = aic + (2 * k * (k + 1)) / (n - k - 1) if (n - k - 1) > 0 else np.nan\n",
    "    bic  = n * np.log(rss / n) + k * np.log(n)\n",
    "\n",
    "    return {\n",
    "        \"n\": n, \"k\": k, \"RSS\": rss, \"TSS\": tss, \"R2\": r2,\n",
    "        \"AIC\": aic, \"AICc\": aicc, \"BIC\": bic,\n",
    "        \"params\": popt, \"SE\": se, \"t\": tvals, \"p\": pvals,\n",
    "        \"yhat\": yhat\n",
    "    }\n",
    "\n",
    "def format_summary(title, param_names, stats_dict):\n",
    "    lines = []\n",
    "    lines.append(f\"{title}\")\n",
    "    lines.append(\"-\" * len(title))\n",
    "    lines.append(f\"n={stats_dict['n']}  k={stats_dict['k']}\")\n",
    "    lines.append(f\"R² = {stats_dict['R2']:.4f}\")\n",
    "    lines.append(f\"AIC = {stats_dict['AIC']:.3f}   AICc = {stats_dict['AICc']:.3f}   BIC = {stats_dict['BIC']:.3f}\")\n",
    "    lines.append(f\"RSS = {stats_dict['RSS']:.3g}\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"Parameters (estimate ± SE) [t, p]:\")\n",
    "    for name, est, se, tval, pval in zip(param_names, stats_dict[\"params\"], stats_dict[\"SE\"], stats_dict[\"t\"], stats_dict[\"p\"]):\n",
    "        pm = \"±\"\n",
    "        lines.append(f\"  {name:>6s} = {est:.6g} {pm} {se:.6g}   [t={tval:.3f}, p={pval:.3g}]\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "# -----------------------------\n",
    "# Main: fit, plot, annotate, save\n",
    "# -----------------------------\n",
    "def compare_and_plot(x, y, out_visdir, out_datadir, title=\"Power-law vs Exponential decay\"):\n",
    "    out_visdir = Path(out_visdir)\n",
    "    out_visdir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    out_datadir = Path(out_datadir)\n",
    "    out_datadir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Fit nonlinear models (use robust-ish starting guesses)\n",
    "    # tweak p0 if needed for your data scale\n",
    "    popt_exp, pcov_exp = curve_fit(exp_decay, x, y, p0=(np.max(y), 0.01, np.min(y)))\n",
    "    popt_pow, pcov_pow = curve_fit(power_law, x, y, p0=(np.max(y), 1.0))\n",
    "\n",
    "    stats_exp = fit_stats(x, y, exp_decay, popt_exp, pcov_exp)\n",
    "    stats_pow = fit_stats(x, y, power_law, popt_pow, pcov_pow)\n",
    "\n",
    "    # Prepare plot\n",
    "    fig, ax = plt.subplots(figsize=(7, 5))\n",
    "    ax.scatter(x, y, label=\"data\")\n",
    "    xs = np.linspace(np.min(x), np.max(x), 300)\n",
    "    ax.plot(xs, exp_decay(xs, *popt_exp),color='green' ,linestyle=\"--\", label=\"Exponential fit\")\n",
    "    ax.plot(xs, power_law(xs, *popt_pow),color='orange' ,linestyle=\"--\", label=\"Power-law fit\")\n",
    "\n",
    "    ax.set_xlabel(\"Number of Mappings\")\n",
    "    ax.set_ylabel(\"Block Size\")\n",
    "    ax.set_title(title)\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "\n",
    "    # Decide best by AIC (lower is better)\n",
    "    best = \"Exponential\" if stats_exp[\"AIC\"] < stats_pow[\"AIC\"] else \"Power-law\"\n",
    "\n",
    "    # Text box (short version) added to the plot\n",
    "    box_txt = (\n",
    "        f\"Best (AIC): {best}\\n\"\n",
    "        f\"Exp:  R²={stats_exp['R2']:.3f}, AIC={stats_exp['AIC']:.1f}\\n\"\n",
    "        f\"      a={popt_exp[0]:.3g}, b={popt_exp[1]:.3g}, c={popt_exp[2]:.3g}\\n\"\n",
    "        f\"Pow:  R²={stats_pow['R2']:.3f}, AIC={stats_pow['AIC']:.1f}\\n\"\n",
    "        f\"      a={popt_pow[0]:.3g}, b={popt_pow[1]:.3g}\"\n",
    "    )\n",
    "    ax.text(\n",
    "        0.60, 0.98, box_txt,\n",
    "        transform=ax.transAxes, va=\"top\", ha=\"left\",\n",
    "        fontsize=9, bbox=dict(boxstyle=\"round\", alpha=0.1)\n",
    "    )\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(out_visdir / \"fit_comparison.png\", dpi=150)\n",
    "    plt.close(fig)\n",
    "\n",
    "    # Write full summaries\n",
    "    exp_txt = format_summary(\"Exponential: y = a * exp(-b*x) + c\", [\"a\", \"b\", \"c\"], stats_exp)\n",
    "    pow_txt = format_summary(\"Power-law: y = a * x^(-b)\", [\"a\", \"b\"], stats_pow)\n",
    "\n",
    "    (out_datadir / \"exp_fit_summary.txt\").write_text(exp_txt)\n",
    "    (out_datadir / \"power_fit_summary.txt\").write_text(pow_txt)\n",
    "\n",
    "    # Also print to console (optional)\n",
    "    print(exp_txt, \"\\n\")\n",
    "    print(pow_txt, \"\\n\")\n",
    "    print(f\"Saved figure to {out_visdir/'fit_comparison.png'}\")\n",
    "    print(f\"Saved summaries to {out_datadir/'exp_fit_summary.txt'} and {out_datadir/'power_fit_summary.txt'}\")\n",
    "\n",
    "qnum = curated_df['qseqid'].value_counts().sort_index()\n",
    "qlen = curated_df.groupby('qseqid')['qlen'].first().sort_index()\n",
    "\n",
    "# Combine into one DataFrame\n",
    "qnum_len_df = pd.DataFrame({\n",
    "    \"qnum\": qnum,\n",
    "    \"qlen\": qlen\n",
    "})\n",
    "\n",
    "# Save to TSV\n",
    "qnum_len_tsv = output_map_data_dir / \"qnum_qlen_table.tsv\"\n",
    "qnum_len_df.to_csv(qnum_len_tsv, sep=\"\\t\", index=True)\n",
    "\n",
    "x = qnum.values\n",
    "y = qlen.values\n",
    "compare_and_plot(x, y, out_visdir=output_map_vis_dir, out_datadir=output_map_data_dir)\n",
    "\n",
    "#### - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "\n",
    "#### - - Total number of mapped bases - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "\n",
    "# I apply the function 'total_coverage' to avoid map the same region multiple times\n",
    "sorted_df = alignment_absolute_start_end(blast_df=curated_df).sort_values(['sseqid', 'a.sstart', 'a.send'])\n",
    "total_coverage_s = sorted_df.groupby('sseqid').apply(lambda x: total_coverage(x, use='subject'))\n",
    "\n",
    "curated_df['coverage'] = curated_df['sseqid'].map(total_coverage_s)\n",
    "\n",
    "mapped_bases = curated_df.groupby('sseqid')[['coverage','slen']].\\\n",
    "                          first().\\\n",
    "                          apply(lambda x: x['coverage'] * x['slen'], axis = 1 ).\\\n",
    "                          sum()\n",
    "\n",
    "#### - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "\n",
    "#### - - Finding the total number of bases - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "\n",
    "unmapped_id = []\n",
    "unmapped_fasta = []\n",
    "\n",
    "# Find unnmapped seeds\n",
    "mapped_subjects = set(curated_df['sseqid'])\n",
    "for record in SeqIO.parse(input_clean_fasta, 'fasta'):\n",
    "    if record.id not in mapped_subjects:\n",
    "        unmapped_id.append(record.id)\n",
    "        unmapped_fasta.append(record.seq)\n",
    "\n",
    "unmapped_df = pd.DataFrame({ 'id': unmapped_id, 'fasta' : unmapped_fasta })\n",
    "\n",
    "if unmapped_df.empty:\n",
    "    unmapped_bases = 0\n",
    "else:\n",
    "    #find the length of each sequence, and sum them all\n",
    "    unmapped_bases = unmapped_df['fasta'].apply(lambda x: len(x)).sum() \n",
    "\n",
    "total_bases = blast_df.groupby('sseqid')['slen'].first().sum() + unmapped_bases\n",
    "#mapped_bases = blast_df['length'].sum()\n",
    "\n",
    "mapped_prop = mapped_bases / total_bases\n",
    "\n",
    "# If mapped_prop is a scalar\n",
    "unmapped_prop = 1 - mapped_prop\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.pie(\n",
    "    [mapped_prop, unmapped_prop],\n",
    "    labels=[\"Mapped\", \"Unmapped\"],\n",
    "    autopct=\"%.1f%%\",        # show percentages\n",
    "    startangle=90,           # start at 12 o’clock\n",
    "    colors=[\"tab:blue\", \"tab:orange\"]\n",
    ")\n",
    "plt.title(\"Mapped vs Unmapped Bases\")\n",
    "plt.savefig(output_map_vis_dir / \"pie.proportion_of_mapped_bases.png\")\n",
    "plt.close()\n",
    "\n",
    "#### - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "\n",
    "#### - - Obtained unnmaped sequence regions - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "\n",
    "gaps_df = unmapped_subject_regions(\n",
    "    curated_df,\n",
    "    subject_id_col=\"sseqid\",\n",
    "    subject_len_col=\"slen\",\n",
    "    sstart_col=\"a.sstart\",\n",
    "    send_col=\"a.send\",\n",
    "    min_pident=90.0,    \n",
    "    min_aln_len=20,     \n",
    "    merge_touching=True,\n",
    "    pad=0                # set >0 to “buffer” mapped regions\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "gaps_df[\"gap_len\"].hist(bins=100)\n",
    "plt.title(\"Gaps size distribution\")\n",
    "plt.xlabel(\"Gap length\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "# Add minor ticks on the x-axis\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_minor_locator(AutoMinorLocator(n=4))  # n=2 means 1 minor tick between each major\n",
    "\n",
    "# (Optional) style the ticks\n",
    "ax.tick_params(axis='x', which='major', length=7, width=1.2)\n",
    "ax.tick_params(axis='x', which='minor', length=4, width=0.8)\n",
    "\n",
    "# (Optional) add gridlines for both major and minor\n",
    "ax.grid(True, which='major', axis='x', linestyle=':', alpha=0.5)\n",
    "\n",
    "plt.savefig(output_map_vis_dir / 'hist.gap_size.png')\n",
    "plt.close()\n",
    "\n",
    "#### - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220a6f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed ✅\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from utils.blast_utils import unmapped_subject_regions\n",
    "\n",
    "# --- Paste your function here (unchanged) ---\n",
    "# unmapped_subject_regions(...)\n",
    "\n",
    "# --- 1) Build a toy BLAST table covering common edge cases ---\n",
    "data = [\n",
    "    # s1: len 100; hits [10,20], [30,40], and a minus-strand [80,60] -> normalized to [60,80]\n",
    "    {\"sseqid\": \"s1\", \"slen\": 100, \"a.sstart\": 10, \"a.send\": 20, \"pident\": 95.0, \"length\": 11},\n",
    "    {\"sseqid\": \"s1\", \"slen\": 100, \"a.sstart\": 30, \"a.send\": 40, \"pident\": 99.0, \"length\": 11},\n",
    "    {\"sseqid\": \"s1\", \"slen\": 100, \"a.sstart\": 80, \"a.send\": 60, \"pident\": 92.0, \"length\": 21},\n",
    "\n",
    "    # s2: len 50; adjacent hits [5,10] and [11,20] (tests merge_touching & n_mapped_intervals)\n",
    "    {\"sseqid\": \"s2\", \"slen\": 50, \"a.sstart\": 5,  \"a.send\": 10, \"pident\": 88.0, \"length\": 6},\n",
    "    {\"sseqid\": \"s2\", \"slen\": 50, \"a.sstart\": 11, \"a.send\": 20, \"pident\": 88.0, \"length\": 10},\n",
    "\n",
    "    # s3: len 30; low-identity hit [3,8] that will be dropped when min_pident>=90\n",
    "    {\"sseqid\": \"s3\", \"slen\": 30, \"a.sstart\": 3,  \"a.send\": 8,  \"pident\": 70.0, \"length\": 6},\n",
    "]\n",
    "blast_df = pd.DataFrame(data)\n",
    "\n",
    "# --- 2) Run the function under different configurations ---\n",
    "gaps_default   = unmapped_subject_regions(blast_df)  # no filters, merge_touching=True, pad=0\n",
    "gaps_filtered  = unmapped_subject_regions(blast_df, min_pident=90)  # drops s2 and s3 hits\n",
    "gaps_pad5      = unmapped_subject_regions(blast_df, pad=5)          # expands mapped regions by 5 bp\n",
    "gaps_notouch   = unmapped_subject_regions(blast_df, merge_touching=False)\n",
    "\n",
    "# --- 3) Assertions: expected complements ---\n",
    "\n",
    "# Helper to pull (start,end) tuples per subject\n",
    "def gaps_of(g, sid):\n",
    "    return list(g[g.sseqid == sid][[\"gap_start\",\"gap_end\"]]\n",
    "                .itertuples(index=False, name=None))\n",
    "\n",
    "# A) Default behavior\n",
    "assert gaps_of(gaps_default, \"s1\") == [(1,9), (21,29), (41,59), (81,100)]\n",
    "# s2 adjacent hits merge into one covered span => two gaps\n",
    "assert gaps_of(gaps_default, \"s2\") == [(1,4), (21,50)]\n",
    "# s3 low-pident hit is still kept (no filter) => two gaps\n",
    "assert gaps_of(gaps_default, \"s3\") == [(1,2), (9,30)]\n",
    "# n_mapped_intervals counts merged mapped blocks\n",
    "assert set(gaps_default[gaps_default.sseqid==\"s2\"][\"n_mapped_intervals\"]) == {1}\n",
    "\n",
    "# B) With min_pident=90: only s1 remains (s2=88, s3=70 removed)\n",
    "assert sorted(gaps_filtered.sseqid.unique()) == [\"s1\"]\n",
    "\n",
    "# C) With padding=5 on s1: mapped spans dilate and merge\n",
    "# [10,20]→[5,25], [30,40]→[25,45] (merge), [60,80]→[55,85] => gaps [1,4], [46,54], [86,100]\n",
    "assert gaps_of(gaps_pad5, \"s1\") == [(1,4), (46,54), (86,100)]\n",
    "\n",
    "# D) merge_touching=False: complement is the same for s2, but n_mapped_intervals changes (2)\n",
    "assert gaps_of(gaps_notouch, \"s2\") == [(1,4), (21,50)]\n",
    "assert set(gaps_notouch[gaps_notouch.sseqid==\"s2\"][\"n_mapped_intervals\"]) == {2}\n",
    "\n",
    "print(\"All tests passed ✅\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OE1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
